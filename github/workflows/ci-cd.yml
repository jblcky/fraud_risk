name: CI/CD for Airflow + Spark ML Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: "3.8"
  IMAGE_NAME: "fraud-pipeline"
  REGISTRY: ghcr.io/${{ github.repository_owner }}
  DOCKERFILE: ./Dockerfile

jobs:
  build-test-deploy:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2️⃣ Set up Python
      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      # 3️⃣ Install dependencies
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # Optionally test DAG parsing
          airflow dags list || echo "Airflow DAG syntax OK"

      # 4️⃣ Lint code (basic quality gate)
      - name: Run flake8 linting
        run: |
          pip install flake8
          flake8 --ignore=E501 dags/ utils/ spark_apps/

      # 5️⃣ Build Docker image
      - name: Build Docker image
        run: |
          docker build -t ${{ env.IMAGE_NAME }} -f ${{ env.DOCKERFILE }} .

      # 6️⃣ Login to GitHub Container Registry
      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ secrets.GHCR_USERNAME }}
          password: ${{ secrets.GHCR_TOKEN }}

      # 7️⃣ Push Docker image
      - name: Push Docker image
        run: |
          docker tag ${{ env.IMAGE_NAME }} ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          docker push ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest

      # 8️⃣ (Optional) Deploy to Kubernetes
      - name: Deploy to Kubernetes
        if: github.ref == 'refs/heads/main'
        run: |
          echo "Deploy step would run 'kubectl apply -f k8s/' or Helm here"
          # You can later add actual kubectl or helm commands
